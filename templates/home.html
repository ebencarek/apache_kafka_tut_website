{% extends "layout.html" %}
{% block content %}
    <h1>Apache Kafka</h1>
    <br>
    <h4>
        Apache Kafka is a distributed streaming platform
    </h4>
    <img src="/static/kafka-diagram.png" class="img-fluid" style="max-width: 50%;" alt="kafka-diagram">
    <p class="small">Image from: <a href="https://www.heroku.com/kafka">https://www.heroku.com/kafka</a></p>
    <p>
        Kafka is designed to facilitate the transfer of a data between different systems or applications
        in an efficient and reliable manner. Kafka runs on a <b>cluster</b> of servers called <b>brokers</b>.
    </p>
    <p>
        Systems can publish <b>records</b> to different categories called <b>topics</b>.
        Topics are separated into <b>partitions</b>, which are ordered immutable sequences
        of records. Paritions are append-only, meaning records cannot be inserted in the
        middle of the partition and records cannot be deleted.
    </p>
    <img src="/static/log_anatomy.png" alt="log-anatomy" class="img-fluid">
    <p class="small">Image from: <a href="https://kafka.apache.org/intro">https://kafka.apache.org/intro</a></p>
    <p>
        Partitions of a topic are distributed among the brokers in the cluster. Each partition is also replicated across a number of other
        brokers in the cluster. The primary broker for a partition is called the <b>leader</b> and the brokers
        containing the replicated partition are called <b>followers</b>. Brokers will act as a leader for some
        partitions and a follower for others for efficient load balancing. The partition's leader services all
        read/write requests to that partition while the followers simply maintain a copy. If the leader ever becomes unavailable,
        one of the followers for that partition will become the new leader.
    </p>
    <br>
    <h4>Data Flow</h4>
    <p>
        <b>Producers</b> publish streams of records to topics. The producer is responsible for choosing which
        partition the record is assigned to. By default, the records are assigned to partitions in a round-robin
        fashion for even distribution.
    </p>
    <p>
        <b>Consumers</b> subscribe to topics to read the records from that topic as they are published. Consumers
        are labeled with a <b>consumer group</b> name, and each record published to a topic is delivered to only
        one consumer within a consumer group.
    </p>
    <p>
        All data that is published to the Kafka cluster is persisted to disk and retained for a configurable amount
        of time. When data is handled in the cluster, Kafka writes to and reads from the disk directly rather than
        maintaining an additional copy of the data in memory. The reason for this is that modern operating systems efficiently
        cache data from the disk in memroy, so maintaining an additional copy of the data in Kafka's program memory would mean
        that two copies of the data would exist in memory at the same time, and data would constantly be copied between user and
        kernel memory space. Working directly from disk allows Kafka to use less memory, meaning the operating
        system has more memory available for caching, and there is less byte-copying occuring when data is being transferred.
    </p>
    <br>
    <h4>Use Cases</h4>
    <p>Kafka can be used as a traditional messaging system, as it provides low latency and high durability.</p>
    <p>
        Kafka is also commonly used for stream processing, where consumers will pull raw data from Kafka topics and
        process the data, then publish the results to new topics for later use.
    </p>
{% endblock %}